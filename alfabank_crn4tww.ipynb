{"cells":[{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding: 10px\">\n","    <h1 class=\"h1-title\" style=\"color: black; font-size: 30px !important;\n","              font-family: Calibri;\">\n","        <b style=\"color: #00FF66; display: inline-block; font-size: 30px !important;\">1 |</b><p style=\"font-size: 30px !important; display: inline-block;\">Encoder-Decoder solution</p>\n","    </h1>\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding: 10px\">\n","    <h2 class=\"h2-title\" style=\"color: black; font-size: 25px !important;\n","              font-family: Calibri;\">\n","        <b style=\"color: #00FF66; display: inline-block; font-size: 25px !important;\">1.1 |</b><p style=\"font-size: 25px !important; display: inline-block;\">Imports</p>\n","    </h2>\n","</div>"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:28:10.596953Z","iopub.status.busy":"2023-10-16T20:28:10.596440Z","iopub.status.idle":"2023-10-16T20:28:20.136329Z","shell.execute_reply":"2023-10-16T20:28:20.135295Z","shell.execute_reply.started":"2023-10-16T20:28:10.596912Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["# math and tables\n","import pandas as pd\n","import numpy as np\n","\n","# for model building\n","import tensorflow as tf\n","\n","# utils\n","from sklearn.model_selection import train_test_split\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding: 10px\">\n","    <h2 class=\"h2-title\" style=\"color: black; font-size: 25px !important;\n","              font-family: Calibri;\">\n","        <b style=\"color: #00FF66; display: inline-block; font-size: 25px !important;\">1.2 |</b><p style=\"font-size: 25px !important; display: inline-block;\">Data Loading, Formatting</p>\n","    </h2>\n","</div>"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:28:20.139359Z","iopub.status.busy":"2023-10-16T20:28:20.138464Z","iopub.status.idle":"2023-10-16T20:28:20.813151Z","shell.execute_reply":"2023-10-16T20:28:20.812147Z","shell.execute_reply.started":"2023-10-16T20:28:20.139322Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Id         int64\n","Data      object\n","Target    object\n","dtype: object"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["train_df = pd.read_csv(\"/kaggle/input/alfabank/df_train.csv\", sep=\";\")\n","test_df = pd.read_csv(\"/kaggle/input/alfabank/df_test.csv\", sep=\";\")\n","\n","train_df.dtypes"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:28:20.814940Z","iopub.status.busy":"2023-10-16T20:28:20.814598Z","iopub.status.idle":"2023-10-16T20:28:21.913508Z","shell.execute_reply":"2023-10-16T20:28:21.912621Z","shell.execute_reply.started":"2023-10-16T20:28:20.814909Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\tlength \n","  train: 7033 \n","  test:  7033\n"]}],"source":["# Since the arrays have varying lengths, we opt for Python lists over numpy ndarrays.\n","# This is because numpy ndarrays require uniform lengths, while lists do not.\n","\n","# The lambda function takes each string, splits it by commas, and converts each segment into an integer.\n","train_df['Data'] = train_df.Data.apply(lambda s: list(map(int, s.split(','))))\n","train_df['Target'] = train_df.Target.apply(lambda s: list(map(int, s.split(','))))\n","test_df['Data'] = test_df.Data.apply(lambda s: list(map(int, s.split(','))))\n","\n","# Ð¡onvert all the train data to python lists\n","x_train = train_df.Data.to_list()\n","x_target = train_df.Target.to_list()\n","x_test = test_df.Data.to_list()\n","\n","print(\"\\tlength\", \"\\n  train:\", len(x_train), \"\\n  test: \", len(x_test))"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:28:21.915272Z","iopub.status.busy":"2023-10-16T20:28:21.914941Z","iopub.status.idle":"2023-10-16T20:28:24.455975Z","shell.execute_reply":"2023-10-16T20:28:24.454824Z","shell.execute_reply.started":"2023-10-16T20:28:21.915241Z"},"trusted":true},"outputs":[],"source":["# The goal here is to augment the training data by breaking down long transaction sequences\n","# into smaller, more manageable subsequences. This is based on the assumption that the 'Target'\n","# column is a direct continuation of the 'Data' column, allowing us to use past transaction data\n","# to predict future transactions.\n","\n","# Set the distance between the start of each subsequence.\n","dist = 28\n","\n","x_train_aug = []\n","x_target_aug = []\n","\n","for seq in x_train:\n","    # Only consider sequences longer than 100 transactions for augmentation.\n","    if len(seq) > 100:\n","        # Create subsequences starting from index 0, stepping by 'dist' each time.\n","        for j in range(0, len(seq), dist):\n","            # If the remaining part of the sequence is less than 60 transactions,\n","            # it's too short to be split further and is skipped.\n","            if len(seq) - j < 60:\n","                break\n","            \n","            i = j\n","            train_seq_aug = []\n","            target_seq_aug = []\n","            \n","            # Collect the next 50 transactions for the training subsequence.\n","            while i < 50 + j:\n","                train_seq_aug.append(seq[i])\n","                i += 1\n","            \n","            # Collect the next 10 transactions for the target subsequence.\n","            while i < 60 + j:\n","                target_seq_aug.append(seq[i])\n","                i += 1\n","            \n","            x_train_aug.append(train_seq_aug)\n","            x_target_aug.append(target_seq_aug)\n","\n","# The result is a set of shorter sequences that can be used to train a model\n","# with a more focused context, potentially improving the prediction accuracy."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:28:24.459423Z","iopub.status.busy":"2023-10-16T20:28:24.459050Z","iopub.status.idle":"2023-10-16T20:28:24.467287Z","shell.execute_reply":"2023-10-16T20:28:24.466326Z","shell.execute_reply.started":"2023-10-16T20:28:24.459390Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["augmented data length: 113808\n"]}],"source":["x_train += x_train_aug\n","x_target += x_target_aug\n","\n","print(\"augmented data length:\", len(x_train))"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:28:24.469752Z","iopub.status.busy":"2023-10-16T20:28:24.468736Z","iopub.status.idle":"2023-10-16T20:28:26.913644Z","shell.execute_reply":"2023-10-16T20:28:26.912608Z","shell.execute_reply.started":"2023-10-16T20:28:24.469717Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["vocab: {0, 5122, 9222, 5641, 5131, 4111, 4112, 5137, 5651, 7699, 5655, 4121, 8220, 5661, 4131, 7210, 7216, 5681, 5169, 5172, 7221, 8244, 5691, 7230, 5697, 5699, 6211, 5192, 5193, 5199, 5200, 5712, 5714, 5713, 5719, 5722, 5211, 9311, 5732, 5733, 5734, 5735, 7273, 8299, 7278, 5231, 4722, 4214, 4215, 7298, 7299, 5251, 5261, 7311, 7829, 7832, 6300, 7841, 7338, 1711, 4784, 4411, 5811, 5812, 5813, 5814, 4789, 5300, 5816, 9399, 9402, 2741, 5309, 5310, 5311, 1731, 4812, 7372, 4814, 7375, 4816, 8398, 5331, 4829, 7395, 742, 7399, 7922, 7932, 7933, 1799, 9211, 7991, 5399, 5912, 7993, 3351, 5921, 5411, 4900, 4899, 8999, 5931, 5422, 5940, 5941, 5942, 5943, 5944, 5945, 5946, 5947, 7996, 5949, 7994, 5948, 7995, 5441, 7997, 5950, 7999, 5451, 5964, 8011, 5965, 5967, 5968, 5969, 5970, 5971, 8021, 5462, 7512, 5977, 5976, 5983, 7011, 7523, 5992, 5993, 5994, 5995, 8043, 7531, 5999, 6513, 7538, 7542, 6010, 5499, 6011, 6012, 8062, 5511, 6536, 8071, 5013, 5532, 5533, 4511, 8099, 6051, 5541, 5542, 3501, 5039, 5044, 5045, 5047, 3000, 8641, 5571, 5065, 7629, 5072, 5074, 5085, 5599, 5094, 5611, 5099, 5621, 5111, 8699, -1, 5631}\n","length: 186\n"]}],"source":["# 0 - start output sequnce symbol\n","# 1 - end output sequnce symbol\n","# -1 - filler symbol\n","\n","# Convert the training data sequences into numpy arrays.\n","encoder_input_seqs = np.asarray([np.array(seq) for seq in x_train])\n","\n","# Prepare the input sequences for the decoder by adding the start symbol at the beginning.\n","# The last element of each sequence is removed.\n","decoder_input_seqs = np.asarray([np.array([0] + seq[:-1]) for seq in x_target])\n","\n","# The target sequences for the decoder are the original sequences without modification.\n","decoder_target_seqs = np.asarray([np.array(seq) for seq in x_target])\n","\n","# Convert the test data sequences into numpy arrays.\n","test_input_seqs = np.asarray([np.array(seq) for seq in x_test])\n","\n","# Create a vocabulary set of MCC codes from the sequences.\n","# This will be used to map each unique MCC code to a unique integer for model processing.\n","# Starting with a set containing the filler symbol.\n","vocab = set([-1])\n","\n","# Update the vocabulary with all unique MCC codes found in the encoder input sequences.\n","for seq in encoder_input_seqs:\n","    vocab.update(set(seq))\n","    \n","# Update the vocabulary with all unique MCC codes found in the decoder input sequences.\n","for seq in decoder_input_seqs:\n","    vocab.update(set(seq))\n","\n","print(f\"vocab: {vocab}\\nlength: {len(vocab)}\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:28:26.915664Z","iopub.status.busy":"2023-10-16T20:28:26.914858Z","iopub.status.idle":"2023-10-16T20:28:27.167712Z","shell.execute_reply":"2023-10-16T20:28:27.166773Z","shell.execute_reply.started":"2023-10-16T20:28:26.915631Z"},"trusted":true},"outputs":[],"source":["# Augment sequences shorter than n elements with some \"zero\" element.\n","# Don't need to do padding to decoder sequences.\n","MAX_INPUT_SEQ_LEN = 50\n","\n","encoder_input_seqs = tf.keras.preprocessing.sequence.pad_sequences(encoder_input_seqs, value=-1, padding='pre', maxlen=MAX_INPUT_SEQ_LEN)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:28:27.169841Z","iopub.status.busy":"2023-10-16T20:28:27.169496Z","iopub.status.idle":"2023-10-16T20:28:27.174134Z","shell.execute_reply":"2023-10-16T20:28:27.173131Z","shell.execute_reply.started":"2023-10-16T20:28:27.169811Z"},"trusted":true},"outputs":[],"source":["# Create a dictionary that maps each unique character (MCC code) to a unique index.\n","# This is used to encode MCC codes into indices.\n","ch2idx_d = {ch:i for i, ch in enumerate(vocab)}\n","# Create a list of characters from the vocabulary, which will be used to decode indices back to MCC codes.\n","idx2ch_l = list(vocab)\n","\n","# Define lambda functions.\n","ch2idx = lambda ch: ch2idx_d[ch]\n","idx2ch = lambda idx: idx2ch_l[idx]"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:28:27.176781Z","iopub.status.busy":"2023-10-16T20:28:27.175843Z","iopub.status.idle":"2023-10-16T20:28:31.257929Z","shell.execute_reply":"2023-10-16T20:28:31.256878Z","shell.execute_reply.started":"2023-10-16T20:28:27.176752Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["example: [ 78  74  78 150 150  97  78  78  78  78  98  98  74  98  98 150  74  74\n"," 150 150 150  78  78  78  78  78  98  74  98 150  74  98  74  98  74  98\n","  78 150  98  74  98 150  78 150  78  78  78  78  78  78]\n"]}],"source":["# Ð¡onvert inputs and targets to indexes.\n","encoder_input_seqs = np.asarray([np.asarray([ch2idx(el) for el in seq]) for seq in encoder_input_seqs])\n","decoder_input_seqs = np.asarray([np.asarray([ch2idx(el) for el in seq]) for seq in decoder_input_seqs])\n","decoder_target_seqs = np.asarray([np.asarray([ch2idx(el) for el in seq]) for seq in decoder_target_seqs])\n","test_input_seqs = np.asarray([np.asarray([ch2idx(el) for el in seq]) for seq in test_input_seqs])\n","\n","print(\"example:\", encoder_input_seqs[0])"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:28:31.260107Z","iopub.status.busy":"2023-10-16T20:28:31.259429Z","iopub.status.idle":"2023-10-16T20:28:31.310194Z","shell.execute_reply":"2023-10-16T20:28:31.309215Z","shell.execute_reply.started":"2023-10-16T20:28:31.260072Z"},"trusted":true},"outputs":[],"source":["encoder_input_seqs_train, encoder_input_seqs_val, decoder_input_seqs_train, decoder_input_seqs_val, decoder_target_seqs_train, decoder_target_seqs_val = \\\n","train_test_split(encoder_input_seqs, decoder_input_seqs, decoder_target_seqs, test_size=0.15, random_state=42)"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding: 10px\">\n","    <h2 class=\"h2-title\" style=\"color: black; font-size: 25px !important;\n","              font-family: Calibri;\">\n","        <b style=\"color: #00FF66; display: inline-block; font-size: 25px !important;\">1.3 |</b><p style=\"font-size: 25px !important; display: inline-block;\">RNN Model</p>\n","    </h2>\n","</div>"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:28:31.312129Z","iopub.status.busy":"2023-10-16T20:28:31.311533Z","iopub.status.idle":"2023-10-16T20:28:36.742243Z","shell.execute_reply":"2023-10-16T20:28:36.741474Z","shell.execute_reply.started":"2023-10-16T20:28:31.312094Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, None)]       0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, None)]       0           []                               \n","                                                                                                  \n"," encoder (Encoder)              ((None, 256),        340608      ['input_1[0][0]']                \n","                                 (None, 256))                                                     \n","                                                                                                  \n"," decoder (Decoder)              ((None, None, 186),  388410      ['input_2[0][0]',                \n","                                 ((None, 256),                    'encoder[0][0]',                \n","                                 (None, 256)))                    'encoder[0][1]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 729,018\n","Trainable params: 729,018\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["# LSTM models are chosen for this sequence prediction task due to their strengths in handling\n","# sequences where the context and order of events are important. I implement generator model \n","# that will be generating future transactions. \n","\n","h_size = 256\n","emb_size = 64\n","\n","class Encoder(tf.keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        self.embed = tf.keras.layers.Embedding(len(vocab), emb_size, name='embed')\n","        self.lstm3 = tf.keras.layers.LSTM(h_size, return_sequences=False, return_state=True, name='lstm_enc')\n","        \n","    def call(self, x):\n","        out = self.embed(x)\n","        out, h, c = self.lstm3(out)\n","        state = (h, c)\n","        \n","        return state\n","    \n","    \n","class Decoder(tf.keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        self.embed = tf.keras.layers.Embedding(len(vocab), emb_size, name='embed')\n","        self.lstm1 = tf.keras.layers.LSTM(h_size, return_sequences=True, return_state=True, name='lstm_dec')\n","        self.fc = tf.keras.layers.Dense(len(vocab), activation='softmax', name='fc')\n","        self.dropout = tf.keras.layers.Dropout(rate=0.9)\n","        \n","    def call(self, x, init_state):\n","        out = self.embed(x)\n","        out, h, c = self.lstm1(out, initial_state=init_state)\n","        state = (h, c)\n","        out = self.dropout(out)\n","        out = self.fc(out)\n","        \n","        return out, state\n","    \n","    \n","encoder_model = Encoder()\n","decoder_model = Decoder()\n","\n","encoder_inputs = tf.keras.layers.Input(shape=(None, ))\n","decoder_inputs = tf.keras.layers.Input(shape=(None, ))\n","\n","enc_state = encoder_model(encoder_inputs)\n","decoder_outputs, _ = decoder_model(decoder_inputs, enc_state)\n","\n","seq2seq = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","seq2seq.summary()"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding: 10px\">\n","    <h2 class=\"h2-title\" style=\"color: black; font-size: 25px !important;\n","              font-family: Calibri;\">\n","        <b style=\"color: #00FF66; display: inline-block; font-size: 25px !important;\">1.4 |</b><p style=\"font-size: 25px !important; display: inline-block;\">Model Training</p>\n","    </h2>\n","</div>"]},{"cell_type":"code","execution_count":12,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-10-16T20:28:36.743615Z","iopub.status.busy":"2023-10-16T20:28:36.743261Z","iopub.status.idle":"2023-10-16T20:28:57.787009Z","shell.execute_reply":"2023-10-16T20:28:57.785465Z","shell.execute_reply.started":"2023-10-16T20:28:36.743584Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["95/95 [==============================] - 21s 122ms/step - loss: 3.0719 - accuracy: 0.2359 - val_loss: 2.3659 - val_accuracy: 0.3493\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7eb4b61ed120>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["BATCH_SIZE = 1024\n","EPOCHS = 1000\n","loss = tf.losses.SparseCategoricalCrossentropy()\n","seq2seq.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n","\n","seq2seq.fit([encoder_input_seqs_train, decoder_input_seqs_train], decoder_target_seqs_train,\n","           validation_data=([encoder_input_seqs_val, decoder_input_seqs_val], decoder_target_seqs_val), \n","           batch_size=BATCH_SIZE,\n","           epochs=EPOCHS)"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding: 10px\">\n","    <h2 class=\"h2-title\" style=\"color: black; font-size: 25px !important;\n","              font-family: Calibri;\">\n","        <b style=\"color: #00FF66; display: inline-block; font-size: 25px !important;\">1.5 |</b><p style=\"font-size: 25px !important; display: inline-block;\">Inference</p>\n","    </h2>\n","</div>"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:28:57.789747Z","iopub.status.busy":"2023-10-16T20:28:57.788660Z","iopub.status.idle":"2023-10-16T20:28:57.797200Z","shell.execute_reply":"2023-10-16T20:28:57.795933Z","shell.execute_reply.started":"2023-10-16T20:28:57.789712Z"},"trusted":true},"outputs":[],"source":["# This inference function takes an input sequence and predicts the sequence of future transactions.\n","def seq2seq_inference(input_seq):\n","    # First, we obtain the initial state of the encoder by passing the input sequence through it\n","    state = encoder_model(input_seq)\n","\n","    # Initialize the target sequence with the start symbol, which is encoded to its corresponding index.\n","    target_seq = np.array([[ch2idx(0)]])\n","    \n","    pred = []\n","    i = 0\n","    # We will predict a fixed number of future transactions.\n","    while i <= 9:\n","        # Pass the current target sequence and the state into the decoder model to get the next output token and updated state.\n","        output_tokens, state = decoder_model(target_seq, state)\n","\n","        # Select the index with the highest probability from the last output.\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        # Decode the index to the corresponding MCC code.\n","        sampled_char = idx2ch(sampled_token_index)\n","        \n","        pred.append(sampled_char)\n","\n","        # Update the target sequence to contain only the last predicted index.\n","        target_seq = np.array([[sampled_token_index]])\n","        \n","        i += 1\n","    \n","    return pred"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:28:57.801948Z","iopub.status.busy":"2023-10-16T20:28:57.801682Z","iopub.status.idle":"2023-10-16T20:39:44.337606Z","shell.execute_reply":"2023-10-16T20:39:44.336702Z","shell.execute_reply.started":"2023-10-16T20:28:57.801925Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["7033\n","0\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n"]}],"source":["# predictions\n","print(len(test_input_seqs))\n","\n","pred = []\n","i = 0\n","for el in test_input_seqs:\n","    pred.append(seq2seq_inference(np.asarray([el])))\n","    \n","    if i % 1000 == 0:\n","        print(i)\n","        \n","    i += 1"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:39:44.339417Z","iopub.status.busy":"2023-10-16T20:39:44.338875Z","iopub.status.idle":"2023-10-16T20:39:44.967253Z","shell.execute_reply":"2023-10-16T20:39:44.966193Z","shell.execute_reply.started":"2023-10-16T20:39:44.339384Z"},"trusted":true},"outputs":[],"source":["# convert predictions to DataFrame, taking rows from \"1:-1\" element to remove \"[\" and \"]\"\n","pred = np.asarray(pred)\n","pred1 = [np.array2string(np.array(array))[1:-1] for array in pred]\n","pred_df = pd.DataFrame(pred1, columns=['Predicted'])"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:39:44.969841Z","iopub.status.busy":"2023-10-16T20:39:44.968867Z","iopub.status.idle":"2023-10-16T20:39:45.008412Z","shell.execute_reply":"2023-10-16T20:39:45.007601Z","shell.execute_reply.started":"2023-10-16T20:39:44.969804Z"},"trusted":true},"outputs":[],"source":["# saving\n","pred_df.index.rename('Id', inplace=True )\n","pred_df.to_csv('/kaggle/working/submission.csv')"]},{"cell_type":"markdown","metadata":{},"source":["Unfortunately, it was not possible to get a good score on this metric with this solution"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding: 10px\">\n","    <h1 class=\"h1-title\" style=\"color: black; font-size: 30px !important;\n","              font-family: Calibri;\">\n","        <b style=\"color: #00FF66; display: inline-block; font-size: 30px !important;\">2 |</b><p style=\"font-size: 30px !important; display: inline-block;\">Statistic solution</p>\n","    </h1>\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding: 10px\">\n","    <h2 class=\"h2-title\" style=\"color: black; font-size: 25px !important;\n","              font-family: Calibri;\">\n","        <b style=\"color: #00FF66; display: inline-block; font-size: 25px !important;\">2.1 |</b><p style=\"font-size: 25px !important; display: inline-block;\">Imports</p>\n","    </h2>\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["in addition to the previous imports add **collections.Counter**"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:39:45.010023Z","iopub.status.busy":"2023-10-16T20:39:45.009657Z","iopub.status.idle":"2023-10-16T20:39:45.014622Z","shell.execute_reply":"2023-10-16T20:39:45.013492Z","shell.execute_reply.started":"2023-10-16T20:39:45.009987Z"},"trusted":true},"outputs":[],"source":["# utils\n","from collections import Counter"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding: 10px\">\n","    <h2 class=\"h2-title\" style=\"color: black; font-size: 25px !important;\n","              font-family: Calibri;\">\n","        <b style=\"color: #00FF66; display: inline-block; font-size: 25px !important;\">2.2 |</b><p style=\"font-size: 25px !important; display: inline-block;\">Functions</p>\n","    </h2>\n","</div>"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:39:45.016518Z","iopub.status.busy":"2023-10-16T20:39:45.015916Z","iopub.status.idle":"2023-10-16T20:39:45.025395Z","shell.execute_reply":"2023-10-16T20:39:45.024621Z","shell.execute_reply.started":"2023-10-16T20:39:45.016488Z"},"trusted":true},"outputs":[],"source":["# https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n","# https://www.kaggle.com/code/prampampam/baseline-popular-transactions/\n","def apk(actual, predicted, k=10):\n","    if len(predicted) > k:\n","        predicted = predicted[:k]\n","\n","    score = 0.0\n","    num_hits = 0.0\n","\n","    for i, p in enumerate(predicted):\n","        if p in actual and p not in predicted[:i]:\n","            num_hits += 1.0\n","            score += num_hits / (i+1.0)\n","\n","    if not actual:\n","        return 0.0\n","\n","    return score / min(len(actual), k)\n","\n","def mapk(actual, predicted, k=10):\n","    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding: 10px\">\n","    <h2 class=\"h2-title\" style=\"color: black; font-size: 25px !important;\n","              font-family: Calibri;\">\n","        <b style=\"color: #00FF66; display: inline-block; font-size: 25px !important;\">2.3 |</b><p style=\"font-size: 25px !important; display: inline-block;\">Data Loading, Formatting</p>\n","    </h2>\n","</div>"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:39:45.027542Z","iopub.status.busy":"2023-10-16T20:39:45.026477Z","iopub.status.idle":"2023-10-16T20:39:45.410403Z","shell.execute_reply":"2023-10-16T20:39:45.409457Z","shell.execute_reply.started":"2023-10-16T20:39:45.027513Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Id         int64\n","Data      object\n","Target    object\n","dtype: object"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["df_train = pd.read_csv(\"/kaggle/input/alfabank/df_train.csv\", sep=\";\")\n","df_test = pd.read_csv(\"/kaggle/input/alfabank/df_test.csv\", sep=\";\")\n","\n","train_df.dtypes"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:39:45.411895Z","iopub.status.busy":"2023-10-16T20:39:45.411542Z","iopub.status.idle":"2023-10-16T20:39:46.542077Z","shell.execute_reply":"2023-10-16T20:39:46.541101Z","shell.execute_reply.started":"2023-10-16T20:39:45.411863Z"},"trusted":true},"outputs":[],"source":["df_train['Data'] = df_train.Data.apply(lambda s: list(map(int, s.split(','))))\n","df_train['Target'] = df_train.Target.apply(lambda s: list(map(int, s.split(','))))\n","df_test['Data'] = df_test.Data.apply(lambda s: list(map(int, s.split(','))))"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding: 10px\">\n","    <h2 class=\"h2-title\" style=\"color: black; font-size: 25px !important;\n","              font-family: Calibri;\">\n","        <b style=\"color: #00FF66; display: inline-block; font-size: 25px !important;\">2.4 |</b><p style=\"font-size: 25px !important; display: inline-block;\">The most popular user transactions</p>\n","    </h2>\n","</div>"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:39:46.543587Z","iopub.status.busy":"2023-10-16T20:39:46.543196Z","iopub.status.idle":"2023-10-16T20:39:46.563479Z","shell.execute_reply":"2023-10-16T20:39:46.562521Z","shell.execute_reply.started":"2023-10-16T20:39:46.543540Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["top 10 codes from target: [4814, 4829, 5331, 5411, 5499, 5541, 5812, 5912, 6010, 6011]\n"]}],"source":["# Take the 10 most popular codes from train[\"Target\"] data (we can take codes from test data instead)\n","# and convert them to a Python List.\n","top10_codes = df_train['Target'].explode().value_counts().head(10).index.to_list()\n","print('top 10 codes from target:', sorted(top10_codes))"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:39:46.565690Z","iopub.status.busy":"2023-10-16T20:39:46.564832Z","iopub.status.idle":"2023-10-16T20:39:46.572875Z","shell.execute_reply":"2023-10-16T20:39:46.571809Z","shell.execute_reply.started":"2023-10-16T20:39:46.565660Z"},"trusted":true},"outputs":[],"source":["# By metrics, the first elements are more important to guess, \n","# and they are more likely to be the most popular user spendings.\n","\n","# We take the most popular transactions of a particular user for the last n transactions \n","# and add to them the most popular ones on the whole \"Target\" (in case there are less than 10 of them). \n","# And, we add the codes in such a way that they do not repeat, it is important.\n","def get_top_codes(transactions, top_n=10, drop_from=5, last=5):\n","    if len(transactions) > 200 * last:\n","        transactions_stats = sorted(\n","            Counter(transactions[-200 * last:]).items(), \n","            key=lambda x: x[1], \n","            reverse=True)[:top_n]\n","    else:\n","        transactions_stats = sorted(\n","            Counter(transactions).items(), \n","            key=lambda x: x[1], \n","            reverse=True)[:top_n]\n","\n","    # Filter out the top MCC codes that occur at least 'drop_from' times.\n","    top_codes = [mcc_code for (mcc_code, count) in transactions_stats if count >= drop_from]\n","    # Identify the most popular MCC codes across all users' \"Target\" transactions that are not already in the user's top list.\n","    top10_codes_diff = [code for code in top10_codes if code not in top_codes]\n","\n","    return (top_codes + top10_codes_diff)[:10]"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:39:46.574509Z","iopub.status.busy":"2023-10-16T20:39:46.574201Z","iopub.status.idle":"2023-10-16T20:53:14.124140Z","shell.execute_reply":"2023-10-16T20:53:14.123207Z","shell.execute_reply.started":"2023-10-16T20:39:46.574481Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["new_mx: 0.28712452519753817 || x: 0 || y: 0 || z: 0\n","new_mx: 0.29833160113659185 || x: 1 || y: 0 || z: 0\n","new_mx: 0.29987566551337347 || x: 1 || y: 0 || z: 1\n","new_mx: 0.30644249671051893 || x: 2 || y: 0 || z: 0\n","new_mx: 0.30860017062420014 || x: 2 || y: 0 || z: 1\n","new_mx: 0.30860795704603466 || x: 2 || y: 4 || z: 1\n","new_mx: 0.31374303453785896 || x: 3 || y: 0 || z: 0\n","new_mx: 0.31624318123856016 || x: 3 || y: 0 || z: 1\n","new_mx: 0.31889968831743326 || x: 4 || y: 0 || z: 0\n","new_mx: 0.32202800742079857 || x: 4 || y: 0 || z: 1\n","new_mx: 0.32205191399276434 || x: 4 || y: 2 || z: 1\n","new_mx: 0.3229761848338559 || x: 5 || y: 0 || z: 0\n","new_mx: 0.3259975760530289 || x: 5 || y: 0 || z: 1\n","new_mx: 0.3287708625324153 || x: 6 || y: 0 || z: 1\n","new_mx: 0.32877712552389077 || x: 6 || y: 2 || z: 1\n","new_mx: 0.3307926351734115 || x: 7 || y: 0 || z: 1\n","new_mx: 0.33084552641853937 || x: 7 || y: 2 || z: 1\n","new_mx: 0.3324265198756881 || x: 8 || y: 0 || z: 1\n","new_mx: 0.3324772388219707 || x: 8 || y: 2 || z: 1\n","new_mx: 0.33314645920930575 || x: 9 || y: 0 || z: 1\n","new_mx: 0.33335848121892486 || x: 9 || y: 2 || z: 1\n","new_mx: 0.3337267451176878 || x: 10 || y: 2 || z: 1\n"]}],"source":["# pick the best parameters, kind of like a Grid Search\n","mx = 0\n","for x in range(0, 11):\n","    for y in range(0, 20, 2):\n","        for z in range(0, 25):\n","            df_train['pred_baseline_2'] = df_train['Data'].apply(get_top_codes, args=(x, y, z))\n","            if mapk(df_train['Target'], df_train['pred_baseline_2']) > mx:\n","                mx = mapk(df_train['Target'], df_train['pred_baseline_2'])\n","                print(\"new_mx:\", mx, \"|| x:\", x, \"|| y:\", y, \"|| z:\", z)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:53:40.784693Z","iopub.status.busy":"2023-10-16T20:53:40.784330Z","iopub.status.idle":"2023-10-16T20:53:40.933941Z","shell.execute_reply":"2023-10-16T20:53:40.933061Z","shell.execute_reply.started":"2023-10-16T20:53:40.784650Z"},"trusted":true},"outputs":[],"source":["# predictions\n","df_test['Predicted'] = df_test['Data'].apply(get_top_codes, args=(10, 2, 1))"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T20:53:43.154573Z","iopub.status.busy":"2023-10-16T20:53:43.154225Z","iopub.status.idle":"2023-10-16T20:53:43.473886Z","shell.execute_reply":"2023-10-16T20:53:43.473033Z","shell.execute_reply.started":"2023-10-16T20:53:43.154525Z"},"trusted":true},"outputs":[],"source":["# saving\n","submission = df_test[['Id', 'Predicted']]\n","submission['Predicted'] = [np.array2string(np.array(array))[1:-1] for array in submission['Predicted'].to_list()]\n","submission.to_csv('submissionnew.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["with this solution I got score on public df - 0.28925"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
